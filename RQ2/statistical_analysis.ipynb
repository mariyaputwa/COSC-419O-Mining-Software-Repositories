{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6413f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency, mannwhitneyu\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03c50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"aggregated_repo_metrics_with_types.csv\"\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ab23d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CSV Data Loaded Successfully:\\n\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFACTORING_CATEGORIES = {\n",
    "    \"Naming Improvements\": [],\n",
    "    \"Parameter Modifications\": [],\n",
    "    \"Method Composition\": [],\n",
    "    \"Method Movement\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f359aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "refactoring_category_counts_ai = defaultdict(int)\n",
    "refactoring_category_counts_human = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b28da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in REFACTORING_CATEGORIES.keys():\n",
    "    ai_total = df[df['Human/AI-Coauthored'] == 'AI-Coauthored'][category].sum()\n",
    "    human_total = df[df['Human/AI-Coauthored'] == 'Human Written'][category].sum()\n",
    "    refactoring_category_counts_ai[category] = ai_total\n",
    "    refactoring_category_counts_human[category] = human_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69519040",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"\\nReconstructed Refactoring Category Counts:\")\n",
    "print(\"AI-Coauthored:\", refactoring_category_counts_ai)\n",
    "print(\"Human Written:\", refactoring_category_counts_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d2d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Analysis\n",
    "print(\"\\n--- Statistical Analysis ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fdc267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Chi-Squared test for refactoring category distributions\n",
    "print(\"\\nChi-Squared Test for Refactoring Category Distribution:\")\n",
    "categories_for_test_chi2 = []\n",
    "observed_chi2 = []\n",
    "for category in REFACTORING_CATEGORIES.keys():\n",
    "    total_count = refactoring_category_counts_ai[category] + refactoring_category_counts_human[category]\n",
    "    if total_count > 0:\n",
    "        categories_for_test_chi2.append(category)\n",
    "        observed_chi2.append([refactoring_category_counts_ai[category], refactoring_category_counts_human[category]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(categories_for_test_chi2) >= 2:\n",
    "    observed_array_chi2 = np.array(observed_chi2)\n",
    "    chi2_stat, chi2_p_value, chi2_dof, expected_chi2 = chi2_contingency(observed_array_chi2)\n",
    "    print(f\"Categories included: {categories_for_test_chi2}\")\n",
    "    print(f\"Chi-Squared Statistic: {chi2_stat:.4f}, p-value: {chi2_p_value:.4f}\")\n",
    "    print(\"Degrees of Freedom:\", chi2_dof)\n",
    "    print(\"Expected Frequencies:\\n\", expected_chi2) # Print Expected Frequencies\n",
    "\n",
    "    alpha = 0.05\n",
    "    if chi2_p_value < alpha:\n",
    "        print(\"Result: Significant difference in refactoring category distributions found.\")\n",
    "    else:\n",
    "        print(\"Result: No significant difference found in refactoring category distributions.\")\n",
    "else:\n",
    "    print(\"Not enough category data for Chi-Squared test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dc4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Mann-Whitney U tests for numerical metrics\n",
    "print(\"\\nMann-Whitney U Tests for Numerical Metrics:\")\n",
    "numerical_metrics_for_test = [\n",
    "    'Total Refactorings', 'Refactoring Commits Percentage',\n",
    "    'Refactoring Timestamp Difference (days)', 'Number of Refactoring Contributors'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac5cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mann_whitney_results = [] # Initialize list to store results for CSV output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4118af8c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for metric in numerical_metrics_for_test:\n",
    "    ai_data = df[df['Human/AI-Coauthored'] == 'AI-Coauthored'][metric].dropna()\n",
    "    human_data = df[df['Human/AI-Coauthored'] == 'Human Written'][metric].dropna()\n",
    "\n",
    "    if not ai_data.empty and not human_data.empty:\n",
    "        MannU_stat, MannU_p_value = mannwhitneyu(ai_data, human_data, alternative='two-sided') # Perform Mann-Whitney U test\n",
    "        print(f\"\\nMetric: {metric}\")\n",
    "        print(f\"  Mann-Whitney U Statistic: {MannU_stat:.4f}, p-value: {MannU_p_value:.4f}\")\n",
    "\n",
    "        if MannU_p_value < alpha:\n",
    "            print(f\"  Result: Significant difference found in {metric} between AI-Coauthored and Human Written repositories.\")\n",
    "            significant_mannu = True # Flag as significant for CSV output\n",
    "        else:\n",
    "            print(f\"  Result: No significant difference found in {metric} between AI-Coauthored and Human Written repositories.\")\n",
    "            significant_mannu = False\n",
    "\n",
    "        mann_whitney_results.append({ # Append results to list for CSV output\n",
    "            'Test': f'Mann-Whitney U Test: {metric}',\n",
    "            'Statistic': MannU_stat,\n",
    "            'p-value': MannU_p_value,\n",
    "            'Significant': significant_mannu,\n",
    "            'Categories': 'AI vs Human'\n",
    "        })\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nMetric: {metric}\")\n",
    "        print(f\"  Warning: Insufficient data to perform Mann-Whitney U test for {metric} (one or both groups have no data).\")\n",
    "        mann_whitney_results.append({ # Append results to list for CSV output\n",
    "            'Test': f'Mann-Whitney U Test: {metric}',\n",
    "            'Statistic': None,\n",
    "            'p-value': None,\n",
    "            'Significant': None,\n",
    "            'Categories': 'Insufficient data'\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61417ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Statistical Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add77f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this code at the end of your script to save results to CSV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0aec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to hold Chi-Square test results\n",
    "chi2_results = pd.DataFrame({\n",
    "    'Test': ['Chi-Squared Test for Refactoring Categories'],\n",
    "    'Statistic': [chi2_stat],\n",
    "    'p-value': [chi2_p_value],\n",
    "    'Significant': [chi2_p_value < alpha],\n",
    "    'Categories': [', '.join(categories_for_test_chi2)]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc0461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to hold Mann-Whitney U test results\n",
    "mw_results_df = pd.DataFrame(mann_whitney_results)\n",
    "all_results = pd.concat([chi2_results, mw_results_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "results_file = '/home/mariya/Documents/Year 4/Data Mining/analysis/statistical_analysis_results.csv'\n",
    "all_results.to_csv(results_file, index=False)\n",
    "print(f\"\\nStatistical analysis results saved to: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ee8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also save raw category counts for reference\n",
    "category_counts = pd.DataFrame({\n",
    "    'Category': list(REFACTORING_CATEGORIES.keys()),\n",
    "    'AI-Coauthored': [refactoring_category_counts_ai[cat] for cat in REFACTORING_CATEGORIES.keys()],\n",
    "    'Human Written': [refactoring_category_counts_human[cat] for cat in REFACTORING_CATEGORIES.keys()]\n",
    "})\n",
    "counts_file = '/home/mariya/Documents/Year 4/Data Mining/analysis/refactoring_category_counts.csv'\n",
    "category_counts.to_csv(counts_file, index=False)\n",
    "print(f\"Refactoring category counts saved to: {counts_file}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

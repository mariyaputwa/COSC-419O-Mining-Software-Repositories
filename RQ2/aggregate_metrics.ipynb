{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import all necessary libraries including os, csv, json, subprocess, git, datetime, pandas, scipy, matplotlib for visualization, and collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import subprocess\n",
    "import git\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Repository Data\n",
    "Create the list of repositories with metadata including name, URL, type (AI-Coauthored or Human Written), AI tool used, and AI-coauthorship mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories = [\n",
    "    {\n",
    "        \"name\": \"MeowAI\",\n",
    "        \"url\": \"https://github.com/charlie-captain/MeowAI.git\",\n",
    "        \"type\": \"AI-Coauthored\",\n",
    "        \"ai_tool\": \"GitHub Copilot\",\n",
    "        \"ai_mention\": \"Commit messages indicate 'Co-authored-by: GitHub Copilot'\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"cryptocurrency\",\n",
    "        \"url\": \"https://github.com/antonioparraga/cryptocurrency.git\",\n",
    "        \"type\": \"AI-Coauthored\",\n",
    "        \"ai_tool\": \"GitHub Copilot\",\n",
    "        \"ai_mention\": \"AI-coauthorship noted in commits\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"AutoScheduler\",\n",
    "        \"url\": \"https://github.com/zhengyue08/AutoScheduler.git\",\n",
    "        \"type\": \"AI-Coauthored\",\n",
    "        \"ai_tool\": \"GitHub Copilot\",\n",
    "        \"ai_mention\": \"README and commit notes mention AI assistance\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"argos-ai-adventure\",\n",
    "        \"url\": \"https://github.com/argosopentech/argos-ai-adventure.git\",\n",
    "        \"type\": \"AI-Coauthored\",\n",
    "        \"ai_tool\": \"GitHub Copilot\",\n",
    "        \"ai_mention\": \"‘Co-authored-by: GitHub Copilot’ appears in commit messages\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ai-generated-games\",\n",
    "        \"url\": \"https://github.com/alexkorep/ai-generated-games.git\",\n",
    "        \"type\": \"AI-Coauthored\",\n",
    "        \"ai_tool\": \"GitHub Copilot\",\n",
    "        \"ai_mention\": \"AI-generated commits detected via commit annotations\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ascii-games\",\n",
    "        \"url\": \"https://github.com/willnippard/ascii-games.git\",\n",
    "        \"type\": \"AI-Coauthored\",\n",
    "        \"ai_tool\": \"GitHub Copilot\",\n",
    "        \"ai_mention\": \"Indications in commit messages that AI assistance was used\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"vscode-python-github-copilot-wsl2\",\n",
    "        \"url\": \"https://github.com/buanzo/vscode-python-github-copilot-wsl2.git\",\n",
    "        \"type\": \"AI-Coauthored\",\n",
    "        \"ai_tool\": \"GitHub Copilot\",\n",
    "        \"ai_mention\": \"Repository name and commits clearly reference GitHub Copilot\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"written_by_chatgpt\",\n",
    "        \"url\": \"https://github.com/hozgur/written_by_chatgpt.git\",\n",
    "        \"type\": \"AI-Coauthored\",\n",
    "        \"ai_tool\": \"ChatGPT\",\n",
    "        \"ai_mention\": \"Repository title and commit messages indicate ChatGPT involvement\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"poker-gpt\",\n",
    "        \"url\": \"https://github.com/thebyrd/poker-gpt.git\",\n",
    "        \"type\": \"AI-Coauthored\",\n",
    "        \"ai_tool\": \"ChatGPT\",\n",
    "        \"ai_mention\": \"Title suggests GPT involvement; commit annotations note AI assistance\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"PyTaskBar\",\n",
    "        \"url\": \"https://github.com/Grassboy/PyTaskBar.git\",\n",
    "        \"type\": \"AI-Coauthored\",\n",
    "        \"ai_tool\": \"GitHub Copilot\",\n",
    "        \"ai_mention\": \"Commit history shows ‘Co-authored-by: GitHub Copilot’\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"python-frameworks-benchmark\",\n",
    "        \"url\": \"https://github.com/startmatter/python-frameworks-benchmark.git\",\n",
    "        \"type\": \"Human Written\",\n",
    "        \"ai_tool\": \"N/A\",\n",
    "        \"ai_mention\": \"N/A\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"msspray\",\n",
    "        \"url\": \"https://github.com/0xZDH/msspray.git\",\n",
    "        \"type\": \"Human Written\",\n",
    "        \"ai_tool\": \"N/A\",\n",
    "        \"ai_mention\": \"N/A\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"pytorch-res2net\",\n",
    "        \"url\": \"https://github.com/4uiiurz1/pytorch-res2net.git\",\n",
    "        \"type\": \"Human Written\",\n",
    "        \"ai_tool\": \"N/A\",\n",
    "        \"ai_mention\": \"N/A\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"pytorch-dimenet\",\n",
    "        \"url\": \"https://github.com/akirasosa/pytorch-dimenet.git\",\n",
    "        \"type\": \"Human Written\",\n",
    "        \"ai_tool\": \"N/A\",\n",
    "        \"ai_mention\": \"N/A\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CRIME-poc\",\n",
    "        \"url\": \"https://github.com/mpgn/crime-poc.git\",\n",
    "        \"type\": \"Human Written\",\n",
    "        \"ai_tool\": \"N/A\",\n",
    "        \"ai_mention\": \"N/A\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"voxceleb-luigi\",\n",
    "        \"url\": \"https://github.com/maxhollmann/voxceleb-luigi.git\",\n",
    "        \"type\": \"Human Written\",\n",
    "        \"ai_tool\": \"N/A\",\n",
    "        \"ai_mention\": \"N/A\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"pycamloop\",\n",
    "        \"url\": \"https://github.com/glefundes/pycamloop.git\",\n",
    "        \"type\": \"Human Written\",\n",
    "        \"ai_tool\": \"N/A\",\n",
    "        \"ai_mention\": \"N/A\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Gnip-Insights-Interface\",\n",
    "        \"url\": \"https://github.com/xdevplatform/Gnip-Insights-Interface.git\",\n",
    "        \"type\": \"Human Written\",\n",
    "        \"ai_tool\": \"N/A\",\n",
    "        \"ai_mention\": \"N/A\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"auckland-ai-meetup-x-triage\",\n",
    "        \"url\": \"https://github.com/a-i-joe/auckland-ai-meetup-x-triage.git\",\n",
    "        \"type\": \"Human Written\",\n",
    "        \"ai_tool\": \"N/A\",\n",
    "        \"ai_mention\": \"N/A\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"NJUPT-API\",\n",
    "        \"url\": \"https://github.com/gaoliang/njupt-api.git\",\n",
    "        \"type\": \"Human Written\",\n",
    "        \"ai_tool\": \"N/A\",\n",
    "        \"ai_mention\": \"N/A\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Helper Functions\n",
    "Define utility functions including categorize_refactoring_type, clone_or_update_repo, estimate_loc, and get_commit_metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_refactoring_type(ref_type):\n",
    "    category_mapping = {\n",
    "        # Naming\n",
    "        \"Rename Method\": \"Naming Improvements\",\n",
    "        \"Rename Class\": \"Naming Improvements\",\n",
    "        \"Rename Variable\": \"Naming Improvements\",\n",
    "        \"Rename Parameter\": \"Naming Improvements\",\n",
    "        \n",
    "        # Parameters\n",
    "        \"Add Parameter\": \"Parameter Modifications\",\n",
    "        \"Remove Parameter\": \"Parameter Modifications\",\n",
    "        \"Change Parameter\": \"Parameter Modifications\",\n",
    "        \"Change/Rename Parameter\": \"Parameter Modifications\",\n",
    "        \n",
    "        # Method Composition\n",
    "        \"Extract Method\": \"Method Composition\",\n",
    "        \"Inline Method\": \"Method Composition\",\n",
    "        \n",
    "        # Method Movement\n",
    "        \"Move Method\": \"Method Movement\",\n",
    "        \"Pull Up Method\": \"Method Movement\",\n",
    "        \"Push Down Method\": \"Method Movement\"\n",
    "    }\n",
    "    return category_mapping.get(ref_type, \"Other\")  # Default to \"Other\" if type is unknown\n",
    "\n",
    "# function to clone or update a repository\n",
    "def clone_or_update_repo(repo_url, local_path):\n",
    "    if not os.path.exists(local_path):\n",
    "        print(f\"Cloning {repo_url} into {local_path}\")\n",
    "        git.Repo.clone_from(repo_url, local_path)\n",
    "    else:\n",
    "        print(f\"Repository {local_path} exists. Pulling latest changes.\")\n",
    "        repo = git.Repo(local_path)\n",
    "        repo.remotes.origin.pull()\n",
    "\n",
    "# function to estimate lines of code (LOC) in a repository\n",
    "def estimate_loc(local_path):\n",
    "    total_lines = 0\n",
    "    for root, dirs, files in os.walk(local_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        lines = f.readlines()\n",
    "                    total_lines += sum(1 for line in lines if line.strip())  \n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "    return total_lines\n",
    "\n",
    "# function to extract commit metrics using GitPython\n",
    "def get_commit_metrics(local_path):\n",
    "    repo = git.Repo(local_path)\n",
    "    commits = list(repo.iter_commits())\n",
    "    commit_count = len(commits)\n",
    "    contributors = set(commit.author.email for commit in commits)\n",
    "    loc = estimate_loc(local_path)\n",
    "    commit_dates = [datetime.datetime.fromtimestamp(commit.committed_date) for commit in commits]\n",
    "    all_commit_hashes = set(commit.hexsha for commit in commits)\n",
    "\n",
    "    return commit_count, loc, len(contributors), sorted(commit_dates), all_commit_hashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Directory and Output Settings\n",
    "Set up the directory for cloning repositories and output CSV file names and paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_dir = \"Repos\"  \n",
    "output_csv = \"aggregated_repo_metrics_with_types.csv\"  \n",
    "\n",
    "os.makedirs(repos_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Refactoring Categories\n",
    "Create the REFACTORING_CATEGORIES dictionary that maps specific refactoring types to broader categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFACTORING_CATEGORIES = {\n",
    "    \"Naming Improvements\": [\n",
    "        \"Rename Method\", \"Rename Class\", \"Rename Variable\", \"Rename Parameter\"\n",
    "    ],\n",
    "    \"Parameter Modifications\": [\n",
    "        \"Add Parameter\", \"Remove Parameter\", \"Change Parameter\", \"Change/Rename Parameter\"\n",
    "    ],\n",
    "    \"Method Composition\": [\n",
    "        \"Extract Method\", \"Inline Method\"\n",
    "    ],\n",
    "    \"Method Movement\": [\n",
    "        \"Move Method\", \"Pull Up Method\", \"Push Down Method\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Repository Processing Functions\n",
    "Define functions to process repositories including run_pyref, get_refactoring_commits, get_refactoring_contributors, get_pyref_type_counts, get_most_common_refactoring_type, and get_refactoring_time_diffs_and_avg_timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to run PyRef on a repository\n",
    "def run_pyref(local_path):\n",
    "    cmd = f\"python3 ../PyRef/main.py getrefs -r \\\"{local_path}\\\" -s 10\"\n",
    "    print(f\"Running PyRef for {local_path}\")\n",
    "    try:\n",
    "        subprocess.run(cmd, shell=True, check=True, capture_output=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"PyRef command failed for {local_path}: {e}\")\n",
    "        return None\n",
    "    repo_name = os.path.basename(local_path)\n",
    "    json_file = f\"{repo_name}_data.json\"\n",
    "    if os.path.exists(json_file):\n",
    "        try:\n",
    "            with open(json_file, \"r\") as f:\n",
    "                ref_data = json.load(f)\n",
    "            return ref_data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from {json_file}: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"PyRef JSON output file not found: {json_file}\")\n",
    "        return None\n",
    "\n",
    "# get refactoring commits from PyRef data\n",
    "def get_refactoring_commits(ref_data):\n",
    "    if not ref_data:\n",
    "        return set()\n",
    "    return set(item[\"Commit\"] for item in ref_data)\n",
    "\n",
    "# get refactoring contributors from PyRef data\n",
    "def get_refactoring_contributors(ref_data, local_path):\n",
    "    if not ref_data:\n",
    "        return set()\n",
    "    repo = git.Repo(local_path)\n",
    "    refactoring_commit_hashes = set(item[\"Commit\"] for item in ref_data)\n",
    "    refactoring_contributors = set()\n",
    "    for commit_hash in refactoring_commit_hashes:\n",
    "        commit = repo.commit(commit_hash)\n",
    "        refactoring_contributors.add(commit.author.email)\n",
    "    return refactoring_contributors\n",
    "\n",
    "#  count refactoring types from PyRef data\n",
    "def get_pyref_type_counts(ref_data):\n",
    "    if not ref_data:\n",
    "        return defaultdict(int)\n",
    "    type_counts = defaultdict(int)\n",
    "    for refactoring in ref_data:\n",
    "        ref_type = refactoring.get(\"Refactoring Type\")\n",
    "        if ref_type:\n",
    "            if isinstance(ref_type, list):\n",
    "                for t in ref_type:\n",
    "                    type_counts[t] += 1\n",
    "            else:\n",
    "                type_counts[ref_type] += 1\n",
    "    return type_counts\n",
    "\n",
    "# get the most common refactoring type\n",
    "def get_most_common_refactoring_type(type_counts):\n",
    "    if not type_counts:\n",
    "        return \"None\"\n",
    "    most_common_type = \"None\"\n",
    "    max_count = 0\n",
    "    for ref_type, count in type_counts.items():\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            most_common_type = ref_type\n",
    "    return most_common_type\n",
    "\n",
    "# calculate refactoring time differences and average timestamp\n",
    "def get_refactoring_time_diffs_and_avg_timestamp(ref_data, local_path, commit_dates):\n",
    "    if not ref_data:\n",
    "        return [], 0 \n",
    "\n",
    "    ref_commits = set(item[\"Commit\"] for item in ref_data)\n",
    "    repo = git.Repo(local_path)\n",
    "    ref_dates = []\n",
    "    for commit in repo.iter_commits():\n",
    "        if commit.hexsha in ref_commits:\n",
    "            ref_dates.append(datetime.datetime.fromtimestamp(commit.committed_date))\n",
    "    ref_dates.sort()\n",
    "    time_diffs = []\n",
    "    for i in range(1, len(ref_dates)):\n",
    "        diff = (ref_dates[i] - ref_dates[i-1]).total_seconds()\n",
    "        time_diffs.append(diff)\n",
    "\n",
    "    avg_refactoring_commit_timestamp = 0  \n",
    "    if ref_dates:\n",
    "        timestamp_sum = sum(date.timestamp() for date in ref_dates)  \n",
    "        avg_refactoring_commit_timestamp = timestamp_sum / len(ref_dates)  \n",
    "    return time_diffs, avg_refactoring_commit_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Repositories and Collect Metrics\n",
    "Implement the main processing loop that iterates through repositories, collects metrics, and prepares data for analysis and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process repositories and collect metrics\n",
    "all_time_diffs_ai = []\n",
    "all_time_diffs_human = []\n",
    "refactoring_category_counts_ai = defaultdict(int)\n",
    "refactoring_category_counts_human = defaultdict(int)\n",
    "\n",
    "with open(output_csv, \"w\", newline=\"\") as csvfile:\n",
    "    fieldnames = [\n",
    "        \"Repository Name\", \"Repository Link\", \"Human/AI-Coauthored\",\n",
    "        \"AI Tool Used\", \"AI-coauthorship Mention\", \"Number of Commits\",\n",
    "        \"Lines of Code/Size\", \"# of Contributors\",\n",
    "        \"Total Refactorings\", \"Average Time-to-Refactor (sec)\", \"Refactoring Commits Percentage\",\n",
    "        \"Average Commit Timestamp (Epoch Sec)\", \"Average Refactoring Commit Timestamp (Epoch Sec)\", \"Refactoring Timestamp Difference (days)\",\n",
    "        \"Number of Refactoring Contributors\", \"Most Common Refactoring Type\"\n",
    "    ] + list(REFACTORING_CATEGORIES.keys())\n",
    "\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for repo_info in repositories:\n",
    "        local_path = os.path.join(repos_dir, repo_info[\"name\"])\n",
    "        clone_or_update_repo(repo_info[\"url\"], local_path)\n",
    "\n",
    "        # Get commit metrics\n",
    "        num_commits, loc, num_contributors, commit_dates, all_commit_hashes = get_commit_metrics(local_path)\n",
    "\n",
    "        # Run PyRef and collect refactoring data\n",
    "        ref_data = run_pyref(local_path)\n",
    "        refactoring_commits_hashes = get_refactoring_commits(ref_data)\n",
    "        refactoring_commits_percentage = (len(refactoring_commits_hashes) / num_commits) * 100 if num_commits > 0 else 0\n",
    "\n",
    "        # Calculate time differences and average timestamps\n",
    "        time_diffs, avg_refactoring_commit_timestamp_epoch = get_refactoring_time_diffs_and_avg_timestamp(ref_data, local_path, commit_dates)\n",
    "        avg_time_refactor = sum(time_diffs) / len(time_diffs) if time_diffs else 0\n",
    "\n",
    "        avg_commit_timestamp_epoch = sum(date.timestamp() for date in commit_dates) / len(commit_dates) if commit_dates else 0\n",
    "        timestamp_difference_days = (avg_refactoring_commit_timestamp_epoch - avg_commit_timestamp_epoch) / 86400.0 if avg_refactoring_commit_timestamp_epoch and avg_commit_timestamp_epoch else 0\n",
    "\n",
    "        # Collect refactoring contributors and type counts\n",
    "        refactoring_contributors = get_refactoring_contributors(ref_data, local_path)\n",
    "        num_refactoring_contributors = len(refactoring_contributors)\n",
    "        type_counts = get_pyref_type_counts(ref_data)\n",
    "        most_common_type = get_most_common_refactoring_type(type_counts)\n",
    "\n",
    "        # Count refactoring categories\n",
    "        refactoring_category_counts = defaultdict(int)\n",
    "        total_refactorings = len(ref_data) if ref_data else 0\n",
    "        if ref_data:\n",
    "            for refactoring in ref_data:\n",
    "                ref_type = refactoring.get(\"Refactoring Type\")\n",
    "                if ref_type:\n",
    "                    if isinstance(ref_type, list):\n",
    "                        for single_type in ref_type:\n",
    "                            category = categorize_refactoring_type(single_type)\n",
    "                            refactoring_category_counts[category] += 1\n",
    "                    else:\n",
    "                        category = categorize_refactoring_type(ref_type)\n",
    "                        refactoring_category_counts[category] += 1\n",
    "\n",
    "        # Aggregate time differences and category counts by repository type\n",
    "        if repo_info[\"type\"] == \"AI-Coauthored\":\n",
    "            all_time_diffs_ai.extend(time_diffs)\n",
    "            for category, count in refactoring_category_counts.items():\n",
    "                refactoring_category_counts_ai[category] += count\n",
    "        else:\n",
    "            all_time_diffs_human.extend(time_diffs)\n",
    "            for category, count in refactoring_category_counts.items():\n",
    "                refactoring_category_counts_human[category] += count\n",
    "\n",
    "        # Write repository metrics to CSV\n",
    "        row_data = {\n",
    "            \"Repository Name\": repo_info[\"name\"],\n",
    "            \"Repository Link\": repo_info[\"url\"],\n",
    "            \"Human/AI-Coauthored\": repo_info[\"type\"],\n",
    "            \"AI Tool Used\": repo_info[\"ai_tool\"],\n",
    "            \"AI-coauthorship Mention\": repo_info[\"ai_mention\"],\n",
    "            \"Number of Commits\": num_commits,\n",
    "            \"Lines of Code/Size\": f\"{loc} lines\",\n",
    "            \"# of Contributors\": num_contributors,\n",
    "            \"Total Refactorings\": total_refactorings,\n",
    "            \"Average Time-to-Refactor (sec)\": avg_time_refactor,\n",
    "            \"Refactoring Commits Percentage\": refactoring_commits_percentage,\n",
    "            \"Average Commit Timestamp (Epoch Sec)\": avg_commit_timestamp_epoch,\n",
    "            \"Average Refactoring Commit Timestamp (Epoch Sec)\": avg_refactoring_commit_timestamp_epoch,\n",
    "            \"Refactoring Timestamp Difference (days)\": timestamp_difference_days,\n",
    "            \"Number of Refactoring Contributors\": num_refactoring_contributors,\n",
    "            \"Most Common Refactoring Type\": most_common_type\n",
    "        }\n",
    "        for category in REFACTORING_CATEGORIES.keys():\n",
    "            row_data[category] = refactoring_category_counts.get(category, 0)\n",
    "\n",
    "        writer.writerow(row_data)\n",
    "        print(f\"Processed repository: {repo_info['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate CSV Output\n",
    "Create and write to the CSV file with all the aggregated repository metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_csv, \"w\", newline=\"\") as csvfile:\n",
    "    fieldnames = [\n",
    "        \"Repository Name\", \"Repository Link\", \"Human/AI-Coauthored\",\n",
    "        \"AI Tool Used\", \"AI-coauthorship Mention\", \"Number of Commits\",\n",
    "        \"Lines of Code/Size\", \"# of Contributors\",\n",
    "        \"Total Refactorings\", \"Average Time-to-Refactor (sec)\", \"Refactoring Commits Percentage\",\n",
    "        \"Average Commit Timestamp (Epoch Sec)\", \"Average Refactoring Commit Timestamp (Epoch Sec)\", \"Refactoring Timestamp Difference (days)\",\n",
    "        \"Number of Refactoring Contributors\", \"Most Common Refactoring Type\"\n",
    "    ] + list(REFACTORING_CATEGORIES.keys())\n",
    "\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for repo_info in repositories:\n",
    "        local_path = os.path.join(repos_dir, repo_info[\"name\"])\n",
    "        clone_or_update_repo(repo_info[\"url\"], local_path)\n",
    "\n",
    "        num_commits, loc, num_contributors, commit_dates, all_commit_hashes = get_commit_metrics(local_path)\n",
    "\n",
    "        ref_data = run_pyref(local_path)\n",
    "        refactoring_commits_hashes = get_refactoring_commits(ref_data)\n",
    "        refactoring_commits_percentage = (len(refactoring_commits_hashes) / num_commits) * 100 if num_commits > 0 else 0\n",
    "\n",
    "        # Calculate time differences and average timestamps\n",
    "        time_diffs, avg_refactoring_commit_timestamp_epoch = get_refactoring_time_diffs_and_avg_timestamp(ref_data, local_path, commit_dates)\n",
    "        avg_time_refactor = sum(time_diffs) / len(time_diffs) if time_diffs else 0\n",
    "\n",
    "        avg_commit_timestamp_epoch = sum(date.timestamp() for date in commit_dates) / len(commit_dates) if commit_dates else 0\n",
    "        timestamp_difference_days = (avg_refactoring_commit_timestamp_epoch - avg_commit_timestamp_epoch) / 86400.0 if avg_refactoring_commit_timestamp_epoch and avg_commit_timestamp_epoch else 0\n",
    "\n",
    "        # Collect refactoring contributors and type counts\n",
    "        refactoring_contributors = get_refactoring_contributors(ref_data, local_path)\n",
    "        num_refactoring_contributors = len(refactoring_contributors)\n",
    "        type_counts = get_pyref_type_counts(ref_data)\n",
    "        most_common_type = get_most_common_refactoring_type(type_counts)\n",
    "\n",
    "        # Count refactoring categories\n",
    "        refactoring_category_counts = defaultdict(int)\n",
    "        total_refactorings = len(ref_data) if ref_data else 0\n",
    "        if ref_data:\n",
    "            for refactoring in ref_data:\n",
    "                ref_type = refactoring.get(\"Refactoring Type\")\n",
    "                if ref_type:\n",
    "                    if isinstance(ref_type, list):\n",
    "                        for single_type in ref_type:\n",
    "                            category = categorize_refactoring_type(single_type)\n",
    "                            refactoring_category_counts[category] += 1\n",
    "                    else:\n",
    "                        category = categorize_refactoring_type(ref_type)\n",
    "                        refactoring_category_counts[category] += 1\n",
    "\n",
    "        # Aggregate time differences and category counts by repository type\n",
    "        if repo_info[\"type\"] == \"AI-Coauthored\":\n",
    "            all_time_diffs_ai.extend(time_diffs)\n",
    "            for category, count in refactoring_category_counts.items():\n",
    "                refactoring_category_counts_ai[category] += count\n",
    "        else:\n",
    "            all_time_diffs_human.extend(time_diffs)\n",
    "            for category, count in refactoring_category_counts.items():\n",
    "                refactoring_category_counts_human[category] += count\n",
    "\n",
    "        # Write repository metrics to CSV\n",
    "        row_data = {\n",
    "            \"Repository Name\": repo_info[\"name\"],\n",
    "            \"Repository Link\": repo_info[\"url\"],\n",
    "            \"Human/AI-Coauthored\": repo_info[\"type\"],\n",
    "            \"AI Tool Used\": repo_info[\"ai_tool\"],\n",
    "            \"AI-coauthorship Mention\": repo_info[\"ai_mention\"],\n",
    "            \"Number of Commits\": num_commits,\n",
    "            \"Lines of Code/Size\": f\"{loc} lines\",\n",
    "            \"# of Contributors\": num_contributors,\n",
    "            \"Total Refactorings\": total_refactorings,\n",
    "            \"Average Time-to-Refactor (sec)\": avg_time_refactor,\n",
    "            \"Refactoring Commits Percentage\": refactoring_commits_percentage,\n",
    "            \"Average Commit Timestamp (Epoch Sec)\": avg_commit_timestamp_epoch,\n",
    "            \"Average Refactoring Commit Timestamp (Epoch Sec)\": avg_refactoring_commit_timestamp_epoch,\n",
    "            \"Refactoring Timestamp Difference (days)\": timestamp_difference_days,\n",
    "            \"Number of Refactoring Contributors\": num_refactoring_contributors,\n",
    "            \"Most Common Refactoring Type\": most_common_type\n",
    "        }\n",
    "        for category in REFACTORING_CATEGORIES.keys():\n",
    "            row_data[category] = refactoring_category_counts.get(category, 0)\n",
    "\n",
    "        writer.writerow(row_data)\n",
    "        print(f\"Processed repository: {repo_info['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Statistical Analysis\n",
    "Perform statistical analysis including Mann-Whitney U test to compare refactoring patterns between AI-coauthored and human-written repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform initial Mann-Whitney U test to compare refactoring time differences\n",
    "if all_time_diffs_ai and all_time_diffs_human:\n",
    "    stat, p_value = mannwhitneyu(all_time_diffs_ai, all_time_diffs_human)\n",
    "    print(f\"Mann-Whitney U test results:\")\n",
    "    print(f\"Statistic: {stat}, p-value: {p_value}\")\n",
    "else:\n",
    "    print(\"Not enough data for Mann-Whitney U test.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
